llm_model: "llama3.2"
chunk_size: 1000
chunk_overlap: 200